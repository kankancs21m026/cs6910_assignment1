{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append('../fashnMnist/')\n",
    "from fashnMnist.FashnMnist import FashnMnist\n",
    "from fashnMnist.Preprocessor import Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Load Mnist fafashion dataset using keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2197c32cef0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "classes = ['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot']\n",
    "plt.figure()\n",
    "plt.imshow(x_test[10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Data preprocessing\n",
    "-verify dataset \n",
    "-perform one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split    \n",
    "from keras.datasets import fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "preprocess=Preprocessor(normalization=True)\n",
    "x_trainNorm, y_trainNorm, x_testNorm, y_testNorm=preprocess.Process_Fashon_mnistDataSet(x_train, y_train, x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Class Definition:\n",
    "-----------------------\n",
    "\n",
    "\n",
    "<b>FashnMnist</b>(<br>\n",
    "    x={Features normalized using class Preprocessor}<br>\n",
    "    ,<b>y=</b>[Training Labels.Data should be one hot encoded]<br>\n",
    "    ,<b>lr=</b>[Learning rate ,DataType:{Float}, default:.1]<br>\n",
    "    ,<b>epochs =</b>[Number of epochs]<br>\n",
    "    ,<b>batch=</b>[size of batches under one epoch]       \n",
    "    ,<b>layer1_size=</b>[Total hidden Nurons should present in first hidden layes , DataType{Int}]<br>\n",
    "    ,<b>layer2_size=</b>[Total hidden Nurons should present in second hidden layes , DataType{Int}]<br>\n",
    "    ,<b>layer3_size=</b>[Total hidden Nurons should present in Third hidden layes , DataType{Int}]<br>\n",
    "    ,<b>layer4_size=</b>[Total hidden Nurons should present in fourth hidden layes , DataType{Int}]<br>\n",
    "    ,<b>layer5_size=</b>[Total hidden Nurons should present in fifth hidden layes , DataType{Int}]<br>\n",
    "    ,<b>optimizer=</b><b>['rms','adam','nadam','sgd','mgd','nag' ,default:'mgd']</b><br>\n",
    "    ,<b>initializer=</b><b>['he','xavier','random',default: 'he']</b><br>\n",
    "    ,<b>activation=</b><b>['tanh','sigmoid','relu' default:'tanh']</b><br>\n",
    "    ,<b>weight_decay=</b>[weight decay for L2 regularization ,DataType:Float,default=0]<br>\n",
    "    <b>dropout_rate=</b>[DataType:Float,default=0]<br>   \n",
    "Methods:<br>\n",
    "    <b>train()</b>: Train the model<br>\n",
    "    <b>GetRunResult(x,y)</b>:<br>\n",
    "        <b>-Inputs</b><br>\n",
    "            -x: Normalized features<br>\n",
    "            -y: labels one hot encoded<br>\n",
    "        <br>\n",
    "        <b>-Returns</b><br>\n",
    "            -predicted data<br>\n",
    "            -accurecy<br>\n",
    "            -loss<br>\n",
    "            <br>\n",
    "Example \n",
    "-------------------------------\n",
    "model=<b>FashnMnist(</b><br>x=x_trainNorm,y=y_trainNorm,\n",
    "lr=.001,epochs=10,batch=32,<br>\n",
    "layer1_size=128,layer2_size=64,optimizer=\"nadam\",<br>\n",
    "initializer=\"he\",activation=\"relu\",dropout_rate=.1<br>)\n",
    "                   \n",
    "model.<b>train() </b>  <br>\n",
    "pred,accTrain,lossTrain = model.<b>GetRunResult(x_trainNorm,y_trainNorm)</b><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NAdam \n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting NAdam\n",
      ".....................................\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-7efb3154d111>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                    )\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maccTrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlossTrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGetRunResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_trainNorm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_trainNorm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maccTest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlossTest\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGetRunResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_testNorm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_testNorm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\deepLearnAssignment1\\final\\kj\\fashnMnist\\FashnMnist.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\deepLearnAssignment1\\final\\kj\\fashnMnist\\optimizer\\NAdam.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     42\u001b[0m                 \u001b[0mstep\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m                 \u001b[0mprocessedDataSize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprocessedDataSize\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m                 \u001b[0mm_w\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv_w\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv_b\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdateParam\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mm_w\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv_w\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv_b\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\deepLearnAssignment1\\final\\kj\\fashnMnist\\optimizer\\NAdam.py\u001b[0m in \u001b[0;36mupdateParam\u001b[1;34m(self, m_w, v_w, m_b, v_b, beta1, beta2, epoch)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[0mnagw1\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m             \u001b[0mnagw2\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mbeta1Dash\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDW\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m             \u001b[0mnagw2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnagw2\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mbeta1Hat\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m             \u001b[0mnagw\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnagw1\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mnagw2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model=FashnMnist(x=x_trainNorm,y=y_trainNorm,  lr=.001,  epochs =10, batch=16 ,               \n",
    "                   layer1_size=128,\\\n",
    "                   layer2_size=64,\\\n",
    "                   optimizer=\"nadam\",\\\n",
    "                   initializer=\"he\",\\\n",
    "                   activation=\"relu\",\n",
    "                   weight_decay=1.5\n",
    "                   \n",
    "                   )\n",
    "model.train()\n",
    "_,accTrain,lossTrain = model.GetRunResult(x_trainNorm,y_trainNorm)\n",
    "_,accTest,lossTest =model.GetRunResult(x_testNorm,y_testNorm)    \n",
    "print(accTrain)\n",
    "print(accTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adam \n",
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Adam\n",
      ".....................................\n",
      " steps=1/1 , Accuraacy =88.14 ,Loss=0.32775 \n",
      "Completed\n",
      ".....................................\n",
      "88.14\n",
      "86.02\n"
     ]
    }
   ],
   "source": [
    "modeladam=FashnMnist(x=x_trainNorm,y=y_trainNorm,  lr=.001,  epochs =1, batch=16 ,               \n",
    "                   layer1_size=128,\\\n",
    "                   layer2_size=64,\\\n",
    "                   optimizer=\"adam\",\\\n",
    "                   initializer=\"he\",\\\n",
    "                   activation=\"relu\"\\\n",
    "                   )\n",
    "modeladam.train()\n",
    "_,accTrain,lossTrain = modeladam.GetRunResult(x_trainNorm,y_trainNorm)\n",
    "_,accTest,lossTest =modeladam.GetRunResult(x_testNorm,y_testNorm)    \n",
    "print(accTrain)\n",
    "print(accTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSProp \n",
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting RMSProp\n",
      ".....................................\n",
      " steps=5/5 , Accuraacy =83.5 ,Loss=0.47047  \n",
      "Completed\n",
      ".....................................\n",
      "83.505\n",
      "82.08\n"
     ]
    }
   ],
   "source": [
    "modeladam=FashnMnist(x=x_trainNorm,y=y_trainNorm,  lr=.003,  epochs =5, batch=100 ,               \n",
    "                   layer1_size=32,\\\n",
    "                   #layer2_size=64,\\\n",
    "                   optimizer=\"rms\",\\\n",
    "                   initializer=\"he\",\\\n",
    "                   activation=\"tanh\",\\\n",
    "                   weight_decay=.5,\\\n",
    "                   lossfunction=\"cross\"\\\n",
    "                   )\n",
    "modeladam.train()\n",
    "_,accTrain,lossTrain = modeladam.GetRunResult(x_trainNorm,y_trainNorm)\n",
    "_,accTest,lossTest =modeladam.GetRunResult(x_testNorm,y_testNorm)    \n",
    "print(accTrain)\n",
    "print(accTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MGD\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Momentum Gradient Descent\n",
      ".....................................\n",
      " steps=10/10 , Accuraacy =86.59 ,Loss=0.36855 \n",
      "Completed\n",
      ".....................................\n",
      "86.58500000000001\n",
      "84.44\n"
     ]
    }
   ],
   "source": [
    "modeladam=FashnMnist(x=x_trainNorm,y=y_trainNorm,  lr=.1,  epochs =10, batch=100 ,               \n",
    "                   layer1_size=256,\\\n",
    "                   layer2_size=128,\\\n",
    "                   optimizer=\"mgd\",\\\n",
    "                   initializer=\"he\",\\\n",
    "                   activation=\"tanh\",\\\n",
    "                   weight_decay=.5,\\\n",
    "                   dropout_rate=.1\n",
    "                   )\n",
    "modeladam.train()\n",
    "_,accTrain,lossTrain = modeladam.GetRunResult(x_trainNorm,y_trainNorm)\n",
    "_,accTest,lossTest =modeladam.GetRunResult(x_testNorm,y_testNorm)    \n",
    "print(accTrain)\n",
    "print(accTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NAG \n",
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting NAG\n",
      ".....................................\n",
      " steps=10/10 , Accuraacy =83.14 ,Loss=0.50258 \n",
      "Completed\n",
      ".....................................\n",
      "83.13833333333334\n",
      "82.03\n"
     ]
    }
   ],
   "source": [
    "modeladam=FashnMnist(x=x_trainNorm,y=y_trainNorm,  lr=.5,  epochs =10, batch=100 ,               \n",
    "                   layer1_size=64,\\\n",
    "                   layer2_size=32,\\\n",
    "                   optimizer=\"nag\",\\\n",
    "                   initializer=\"he\",\\\n",
    "                   activation=\"tanh\"\\\n",
    "                  \n",
    "                   )\n",
    "modeladam.train()\n",
    "_,accTrain,lossTrain = modeladam.GetRunResult(x_trainNorm,y_trainNorm)\n",
    "_,accTest,lossTest =modeladam.GetRunResult(x_testNorm,y_testNorm)    \n",
    "print(accTrain)\n",
    "print(accTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD \n",
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....................................\n",
      "Starting Gradient Descent..\n",
      ".....................................\n",
      " steps=10/10 , Accuraacy =70.55 ,Loss=0.97409 \n",
      "Completed\n",
      ".....................................\n",
      "70.55\n",
      "70.19999999999999\n"
     ]
    }
   ],
   "source": [
    "modeladam=FashnMnist(x=x_trainNorm,y=y_trainNorm,  lr=.1,  epochs =10,\\           \n",
    "                   layer1_size=32,\\\n",
    "                   layer2_size=64,\\\n",
    "                   optimizer=\"sgd\",\\\n",
    "                   initializer=\"he\",\\\n",
    "                   activation=\"tanh\",\n",
    "                   )\n",
    "modeladam.train()\n",
    "_,accTrain,lossTrain = modeladam.GetRunResult(x_trainNorm,y_trainNorm)\n",
    "_,accTest,lossTest =modeladam.GetRunResult(x_testNorm,y_testNorm)    \n",
    "print(accTrain)\n",
    "print(accTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
